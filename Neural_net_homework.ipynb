{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplicacion Matricial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Ejemplo en DS** : en inteligencia artificial y ML en la sub-rama \"reinforcement learning\" la \"ecuacion de bellman\" puede aplicarse de manera vectorizada a traves del operar vectores, matrices y escalares en una sola expresion.\n",
    "\n",
    "<img src=\"https://rebornhugo.github.io/assets/images/post_images/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A02/bellman%20equation2.PNG\">\n",
    "\n",
    "* n = numero de estados del sistema.\n",
    "* V(s) = vector que representa el valor esperado para cierto estado\n",
    "* R = recompensa inmediata percibida por el agente al salir de cierto estado.(vector)\n",
    "* P = matriz de transicion de la cadena de Markov sub-yacente.(matriz)\n",
    "* γ = factor de descuento de recompensas futuras(escalar)\n",
    "\n",
    "Calcular V(s) para el siguiente sistema aplicando la ecuación de bellman de manera vectorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.array([0,0,0]) # valor inicial de V(s)\n",
    "R = np.array([10,2,5]) # vector de recompensas\n",
    "P = np.array([[0.5,0.25,0.25],\n",
    "              [0.2,0.40,0.40],\n",
    "              [0.80,0.10,0.10]])  # matriz de transición\n",
    "gamma = 0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.,  2.,  5.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (R+ gamma*np.matmul(P,V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio aplicado en DS**\n",
    "Se tiene una red neuronal sencilla(y simplificada) como la de la siguiente imagen:\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-convolutional-neural/9781788392303/assets/246151fb-7893-448d-b9bb-7a87b387a24b.png\">\n",
    "\n",
    "Donde:\n",
    "* INPUT LAYER: un vector X de tamaño = 2 que representa los datos de entrada\n",
    "* HIDDEN_LAYER :capa oculta con 2 neuronas definidas por los vectores:\n",
    "    * HL1 = [0.25,0.37]\n",
    "    * HL2 = [-8,14]\n",
    "* OUTPUT_LAYER = capa de salida definida por el vector [4,9]\n",
    "\n",
    "Crear una funcion neural_network(X) para calcular:\n",
    "* Calcule la salida de cada neurona en la capa intermedia aplicada a la capa de entrada.\n",
    "* Use el resultado del paso anterior como entrada para la neurona en la capa de salida\n",
    "\n",
    "Utilizando multiplicacion de matrices se debe calcular para cada fila de la matriz de entrada X el valor de las neuronas de la capa intermedia, esto producira una nueva matriz con el mismo numero de filas que X y 2 columnas(1 para cada neurona) , a  los valores de esta matriz se les debe aplicar la funcion \"sigmoid\"(descrita a continuacion) para limitarlos al intervalo de 0 a 1, esto produce una matriz del mismo tamanio pero con valores entre 0 a 1, esta matriz se multiplica matricialmente por la matriz que representa los pesos de la capa de salida  y este proceso produce un nuevo tensor al cual se debe aplicar nuevamente la funcion sigmoid. El resultado debe ser un tensor con el mismo numero de filas que la matriz X y una sola columna(una prediccion para cada fila de X\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*Xu7B5y9gp0iL5ooBj7LtWw.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): #convertir los valores de x al rango de 0 a 1\n",
    "    \n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    condiciones = [x<0, x>=0]\n",
    "    resultados = [0,x]\n",
    "    h =np.select(condiciones,resultados, 0)\n",
    "    return h \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69508477 0.77029895 0.67612055]]\n",
      "[0.69269553]\n"
     ]
    }
   ],
   "source": [
    "H1_W = np.array([[0.712,0.355,0.268],\n",
    "                 [0.112,0.855,0.468]])\n",
    "OL_W = np.array([0.116,0.329,0.708])\n",
    "\n",
    "X =  np.array([[1,1]])\n",
    "\n",
    "H1 = np.matmul(X,H1_W)\n",
    "H1 = sigmoid(H1)  # funcion de activacion: convertir a valores en el intervalo de 0 a 1\n",
    "OL = np.matmul(H1,OL_W)\n",
    "OL = sigmoid(OL)  # funcion de activacion: convertir a valores en el intervalo de 0 a 1\n",
    "\n",
    "print(H1)\n",
    "print(OL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(x):\n",
    "    H1_W = np.array([[0.712,0.355,0.268],\n",
    "                 [0.112,0.855,0.468]])\n",
    "    OL_W = np.array([0.116,0.329,0.708])\n",
    "    H1 = np.matmul(x,H1_W)\n",
    "    H1 = sigmoid(H1)  # funcion de activacion: convertir a valores en el intervalo de 0 a 1\n",
    "    OL = np.matmul(H1,OL_W)\n",
    "    OL = relu(OL)\n",
    "\n",
    "    return OL\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio \n",
    "\n",
    "Implementar en una funcion neural_network(X) la red neuronal definida por la siguiente arquitectura:\n",
    "\n",
    "<img src=\"http://i.imgur.com/UNlffE1.png\">\n",
    "\n",
    "Podemos validar si fue correctamente implementada si usamos como entrada el vector x=[1,1] . Debemos obtener el resultado mostrado en la imagen.\n",
    "\n",
    "Una vez tenemos la implementacion correcta, cambiar la funcion de activacion de la capa de salida por la funcion de activacion ReLu(https://en.wikipedia.org/wiki/Rectifier_(neural_networks)):\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*DfMRHwxY1gyyDmrIAd-gjQ.png\">\n",
    "\n",
    "Luego evaluar la red neuronal sobre la matriz de datos X(de manera vectorizada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85897151, 0.6748703 , 1.14904686, 1.15125178, 1.14187076,\n",
       "       0.72619803, 1.15019715, 1.153     , 1.1500904 , 1.153     ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [0.1,2],\n",
    "    [0.3,0.45],\n",
    "    [5,9],\n",
    "    [12,6],\n",
    "    [7,5],\n",
    "    [0.3,0.8],\n",
    "    [12,5],\n",
    "    [100,200],\n",
    "    [7,8],\n",
    "    [300,1500]])\n",
    "\n",
    "neural_network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8127515352804022"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network([1,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
